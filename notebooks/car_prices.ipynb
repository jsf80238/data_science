{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdfca7d1-2976-4368-afea-c9417d7132a4",
   "metadata": {},
   "source": [
    "# Predicting car prices\n",
    "I am using [this Kaggle dataset](https://www.kaggle.com/datasets/mystifoe77/car-prices).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Links won't work until the link target cells have been executed.\n",
    "</div>\n",
    "\n",
    "This is a work-in-progress. I have gotten as far as:\n",
    "* Preparing the feature set.\n",
    "* Running a multiple linear regression for heart disease and [reaching a conclusion](#heart_disease_linear_regression_conclusion).\n",
    "* Running a Naive Bayes analysis and not finding anything useful.\n",
    "  * [try 1](#bayes_1)\n",
    "  * [try 2](#bayes_2)\n",
    "* Running [XGBoost_ed decision trees](#xgboost) and not finding anything useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f5fe200-ce60-4c34-8c3c-a5713e9af153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import datetime\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import subprocess\n",
    "from zipfile import ZipFile\n",
    "# Imports above are standard library\n",
    "# Imports below are 3rd-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, silhouette_score, f1_score, accuracy_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, ComplementNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from statsmodels.api import qqplot\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from xgboost import XGBClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c1c60-b92d-4785-820a-61750d2a7ed0",
   "metadata": {},
   "source": [
    "## Download credentials\n",
    "You will need your own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facdfcc4-9760-431a-8b7a-8376557bd278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional (you can fetch the data manually using the Kaggle link in the first cell):\n",
    "MY_KAGGLE_USERNAME = \"jsf80238\"\n",
    "MY_KAGGLE_KEY = \"4036359324650e1c13adfc7ba87ff90e\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63968585-b219-46d8-9c7f-216368aefac3",
   "metadata": {},
   "source": [
    "### Kaggle API\n",
    "If you will be downloading from Kaggle you will need your own API key, which you can get by following [these instructions](https://github.com/Kaggle/kaggle-api/blob/main/docs/README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a555e6b-5df1-432b-8c45-dabd1a983e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE_FILE_NAME = \"car_prices.csv\"\n",
    "KAGGLE_DATASET_NAME = \"Car_Prices\"\n",
    "KAGGLE_USER_NAME = \"mystifoe77\"\n",
    "\n",
    "save_file = \"car_prices.df\"  # For larger downloads saving the dataframe locally can save time between runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b19be702-79f1-4452-a478-2b7f29d5c761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaggle_dataset_ref() -> str:\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = MY_KAGGLE_USERNAME\n",
    "    os.environ[\"KAGGLE_KEY\"] = MY_KAGGLE_KEY\n",
    "    import kaggle  # The import itself uses your KAGGLE_KEY, that's why the import is not at the top. Really.\n",
    "    \n",
    "    command = \"kaggle datasets list --csv --search\".split()\n",
    "    #command.append(\"NCHS - Death Rates and Causes of Death\")\n",
    "    result = subprocess.run(command + [KAGGLE_DATASET_NAME], capture_output=True)\n",
    "    data = result.stdout.decode(encoding=\"utf-8\")\n",
    "    csvreader = csv.DictReader(data.splitlines())\n",
    "    for row in csvreader:\n",
    "        title = row[\"title\"]\n",
    "        user_name, _ = row[\"ref\"].split(\"/\")\n",
    "        if title == KAGGLE_DATASET_NAME and user_name == KAGGLE_USER_NAME:\n",
    "            # print(row)\n",
    "            return row[\"ref\"]\n",
    "    else:\n",
    "        raise Exception(\"Could not find a matching Kaggle dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09d5aa23-55b4-4a78-a63a-8340897dc998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe details:\n",
      "558,837 rows\n",
      "StructType([StructField('year', IntegerType(), True), StructField('make', StringType(), True), StructField('model', StringType(), True), StructField('trim', StringType(), True), StructField('body', StringType(), True), StructField('transmission', StringType(), True), StructField('vin', StringType(), True), StructField('state', StringType(), True), StructField('condition', IntegerType(), True), StructField('odometer', IntegerType(), True), StructField('color', StringType(), True), StructField('interior', StringType(), True), StructField('seller', StringType(), True), StructField('mmr', IntegerType(), True), StructField('sellingprice', IntegerType(), True), StructField('saledate', StringType(), True)])\n",
      "+----+---------+-------------------+--------------------+-----------+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+--------------------+\n",
      "|year|     make|              model|                trim|       body|transmission|              vin|state|condition|odometer|color|interior|              seller|  mmr|sellingprice|            saledate|\n",
      "+----+---------+-------------------+--------------------+-----------+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+--------------------+\n",
      "|2015|      Kia|            Sorento|                  LX|        SUV|   automatic|5xyktca69fg566472|   ca|        5|   16639|white|   black|kia motors americ...|20500|       21500|Tue Dec 16 2014 1...|\n",
      "|2015|      Kia|            Sorento|                  LX|        SUV|   automatic|5xyktca69fg561319|   ca|        5|    9393|white|   beige|kia motors americ...|20800|       21500|Tue Dec 16 2014 1...|\n",
      "|2014|      BMW|           3 Series|          328i SULEV|      Sedan|   automatic|wba3c1c51ek116351|   ca|       45|    1331| gray|   black|financial service...|31900|       30000|Thu Jan 15 2015 0...|\n",
      "|2015|    Volvo|                S60|                  T5|      Sedan|   automatic|yv1612tb4f1310987|   ca|       41|   14282|white|   black|volvo na rep/worl...|27500|       27750|Thu Jan 29 2015 0...|\n",
      "|2014|      BMW|6 Series Gran Coupe|                650i|      Sedan|   automatic|wba6b2c57ed129731|   ca|       43|    2641| gray|   black|financial service...|66000|       67000|Thu Dec 18 2014 1...|\n",
      "|2015|   Nissan|             Altima|               2.5 S|      Sedan|   automatic|1n4al3ap1fn326013|   ca|        1|    5554| gray|   black|enterprise vehicl...|15350|       10900|Tue Dec 30 2014 1...|\n",
      "|2014|      BMW|                 M5|                Base|      Sedan|   automatic|wbsfv9c51ed593089|   ca|       34|   14943|black|   black|the hertz corpora...|69000|       65000|Wed Dec 17 2014 1...|\n",
      "|2014|Chevrolet|              Cruze|                 1LT|      Sedan|   automatic|1g1pc5sb2e7128460|   ca|        2|   28617|black|   black|enterprise vehicl...|11900|        9800|Tue Dec 16 2014 1...|\n",
      "|2014|     Audi|                 A4|2.0T Premium Plus...|      Sedan|   automatic|wauffafl3en030343|   ca|       42|    9557|white|   black|  audi mission viejo|32100|       32250|Thu Dec 18 2014 1...|\n",
      "|2014|Chevrolet|             Camaro|                  LT|Convertible|   automatic|2g1fb3d37e9218789|   ca|        3|    4809|  red|   black|  d/m auto sales inc|26300|       17500|Tue Jan 20 2015 0...|\n",
      "+----+---------+-------------------+--------------------+-----------+------------+-----------------+-----+---------+--------+-----+--------+--------------------+-----+------------+--------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('car_prices').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "if os.path.exists(save_file):\n",
    "    pickleRdd = sc.pickleFile(save_file).collect()\n",
    "    df2 = spark.createDataFrame(pickleRdd)\n",
    "else:\n",
    "    dataset_ref = get_kaggle_dataset_ref()\n",
    "    command = f\"kaggle datasets download --unzip --force --file {KAGGLE_FILE_NAME} {dataset_ref}\".split()\n",
    "    result = subprocess.run(command, capture_output=True)\n",
    "    stdout = result.stdout.decode(encoding=\"utf-8\")\n",
    "    stderr = result.stderr.decode(encoding=\"utf-8\")\n",
    "    print(stdout)\n",
    "    print(stderr)\n",
    "    print()\n",
    "    print(\"Directory contents:\")\n",
    "    print(os.linesep.join(sorted(os.listdir(\".\"))))\n",
    "    print()\n",
    "    # Larger downloads are in zip format\n",
    "    if os.path.exists(KAGGLE_FILE_NAME + \".zip\"):\n",
    "        zipped_object = ZipFile(KAGGLE_FILE_NAME + \".zip\")\n",
    "        zipped_object.extract(KAGGLE_FILE_NAME)\n",
    "    \n",
    "    df = spark.read.csv(KAGGLE_FILE_NAME, sep=',', inferSchema=True, header=True)\n",
    "    # df = pd.read_csv(KAGGLE_FILE_NAME)\n",
    "\n",
    "    df.rdd.saveAsPickleFile(save_file)\n",
    "\n",
    "print(\"Dataframe details:\")\n",
    "print(f\"{df.count():,} rows\")\n",
    "print(df.schema)\n",
    "print(df.limit(10).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88ce89-82fa-4aed-b279-534780166550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
